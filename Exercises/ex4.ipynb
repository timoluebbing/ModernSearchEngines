{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 4271 - Exercise 4 - Statistical Ranking\n",
    "\n",
    "Issued: May 7, 2024\n",
    "\n",
    "Due: May 13, 2024\n",
    "\n",
    "Please submit this filled sheet via Ilias by the due date.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generative Relevance Models\n",
    "Generative retrieval models use the probabilistic language model framework for matching queries and documents.\n",
    "\n",
    "a) Implement the `rank()` function sketched below. In class, we discussed two alternative model variants. Choose the query likelihood model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def bag_of_words(text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenize the text\n",
    "    return text.lower().split()\n",
    "\n",
    "#Rank a collection of documents relative to a query using the query likelihood model\n",
    "def rank(Query, Doc):\n",
    "     \n",
    "     Q = bag_of_words(Query)\n",
    "     D = [bag_of_words(d) for d in Doc]\n",
    "\n",
    "     D_counts = [Counter(d) for d in D]\n",
    "     D_lengths = [len(d) for d in D]\n",
    "     \n",
    "     scores = []\n",
    "     \n",
    "     for doc, d_count, d_length in zip(Doc, D_counts, D_lengths):\n",
    "          score = 0\n",
    "          for word in Q:\n",
    "               # Calculate the probability of the word in the document\n",
    "               # Avoid zero probabilities by using smoothing (plus 1)\n",
    "               prob = (d_count[word] + 1) / (d_length + len(set(Q)))\n",
    "\n",
    "               # Sum of log probabilities is equivalent \n",
    "               # to the log of the product of probabilities\n",
    "               score += np.log(prob)\n",
    "\n",
    "          # Add the score of the document to the list of scores per doc\n",
    "          scores.append((doc, score)) \n",
    "\n",
    "     ranks = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "     \n",
    "     return ranks\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the french bulldog is a small breed of domestic dog', -3.58351893845611),\n",
      " ('french is a very french language spoken by the french', -3.58351893845611),\n",
      " ('the french revolution was a period of upheaval in france',\n",
      "  -4.276666119016055)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "Q = 'french bulldog'\n",
    "D = ['the french revolution was a period of upheaval in france', \n",
    "     'the french bulldog is a small breed of domestic dog', \n",
    "     'french is a very french language spoken by the french']\n",
    "\n",
    "pprint(rank(Q, D))   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Probabilistic language models may encounter previously unseen query terms. Explain why this can become problematic and how you would address the issue. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a word has never been seen before, its frequency is zero, and thus its probability is also zero (based on the definition of the query likelihood model).\n",
    "\n",
    "This is problematic because it means that any document containing this term will have a probability of zero, regardless of the presence of other terms.\n",
    "\n",
    "One solution to this problem would be to use smoothing, by adding a small probability to unseen terms. This would avoid zero probabilities. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Relevance Feedback\n",
    "Relevance Feedback allows us to refine the query representation after a round of user interaction with the search results. If organic feedback is not available, we can assume highly ranked documents to be *pseudo* relevant. Discuss the advantages and disadvantages of the pseudo relevance feedback scheme. Think in particular about single versus multiple rounds of feedback."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages\n",
    "1. No user feedback required: It is hard to obtain user feedback since users do not care and will just try a new search query.\n",
    "2. Improved queries as an automatic process with no additional input required: Pseudo relavant documents can help improve the original query by adding and reweighing terms.  \n",
    "\n",
    "### Disadvantages\n",
    "1. Assumption of relavance: Top ranked documents are assumed to be relevant but this is not always the case. \n",
    "2. Query drift: Especially with multiple repetitions of the pseudo relevance feedback method, the new queries drift away from the original intend of the user. More noice is added to the original query as some highly ranked documents are irrelevant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
